\chapter{Medians and Order Statistics}

\section{Minimum and maximum}

\begin{enumerate}

\item[9.1{-}1]{Show that the second smallest of $n$ elements can be found with
$n + \ceil{\lg n} - 2$ comparisons in the worst case. (\emph{Hint:} Also find
the smallest element.)}

\begin{framed}
Lets find first the smallest element. Compare the elements in pairs and discard
the largest element of each pair. The number of elements is now $\ceil{n/2}$.
Repeat this operation recursively to the remaining elements until the smallest
element is found. Since we discard one element in each comparison, the number of
comparisons is the number of elements that is not the smaller.  Thus, $n - 1$
comparisons. Note that the second smallest element can only be greater than the
smallest element. Thus, the second smallest element is among these
$\ceil{\lg n}$ elements that were discarded when compared to the smallest
element. Use the same recursive approach on these $\ceil{\lg n}$ elements to
find the second smallest with $\ceil{\lg n} - 1$ comparisons. The total number
of comparisons in the worst-case is then $n - 1 + \ceil{\lg n}
- 1 = n + \ceil{\lg n} - 2$.
\end{framed}

\item[9.1{-}2]{($\star$) Prove the lower bound of $\ceil{3n/2} - 2$ comparisons
in the worst case to find both the maximum and minimum of $n$ numbers.
(\emph{Hint:} Consider how many numbers are potentially either the maximum or
minimum, and investigate how a comparison affects these counts.)}

\begin{framed}
At the start, any of the $n$ the elements can be both the minimum and the
maximum. After the first comparison, we can discard the largest as not being the
minimum and the smallest as not being the maximum. From now on we have two
options: compare two different elements or compare one of the elements
previously compared with a different element. The first option will decrease by
one both the number of potential minimums and potential maximums, while the
second option will only decrease one of these totals. Thus, the best way to
start is to group the elements in pairs and compare them, which requires
$\floor{n/2}$ comparisons. After comparing all the pairs, we will have
$\ceil{n/2}$ potential maximums and $\ceil{n/2}$ potential minimums. In the
worst-case, those sets are disjoint and must be treated independently. We know
from the previous question that the minimum number of comparisons needed to find
the minimum or the maximum among $\ceil{n/2}$ elements is $\ceil{n/2} - 1$.
Thus, the lower bound to find both the maximum and the minimum of $n$ numbers in
the worst-case is
\[
  \Bigl\lfloor \frac{n}{2} \Bigr\rfloor + 2 \left( \Bigl\lceil \frac{n}{2} \Bigr\rceil - 1 \right).
\]

If $n$ is even, we have
\[
  \Bigl\lfloor \frac{n}{2} \Bigr\rfloor + 2 \left( \Bigl\lceil \frac{n}{2} \Bigr\rceil - 1 \right)
  = \frac{n}{2} + n - 2
  = \frac{3n}{2} - 2
  = \Bigl\lceil \frac{3n}{2} \Bigr\rceil - 2.
\]

If $n$ is odd, we have
\[
  \Bigl\lfloor \frac{n}{2} \Bigr\rfloor + 2 \left( \Bigl\lceil \frac{n}{2} \Bigr\rceil - 1 \right)
  = \frac{n - 1}{2} + (n + 1) - 2
  = \frac{3n - 3}{2}
  = \Bigl\lceil \frac{3n}{2} \Bigr\rceil - 2.
\]
\end{framed}

\end{enumerate}

\newpage

\section{Selection in worst-case linear time}

\begin{enumerate}

\item[9.2-1]{Show that \textsc{Randomized-Select} never makes a recursive call
to a 0-length array.}

\begin{framed}
At the start of each recursive call, a random pivot is chosen. If it happens to
be the $i$th element, the element being searched has been found and is returned
without any additional recursion call. Otherwise, the $i$th element is either
before or after the pivot and a recursive call is made on the side of the
subarray that includes the $i$th element.
\end{framed}

\item[9.2-2]{Argue that the indicator random vartiable $X_k$ and the value
$T(\max(k - 1, n - k))$ are independent.}

\begin{framed}
Both $X_k$ and $T(\max(k - 1, n - k))$ depends on the value of $k$. However, no
matter if $X_k$ is 0 or 1, the value of $T(\max(k - 1, n - k))$ is the same.
\end{framed}

\item[9.2-3]{Write an iterative version of \textsc{Randomized-Select}.}

\begin{framed}
The pseudocode is stated below.

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Randomized-Select-Iterative}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r, i}}{%
  \If{$p == r$}{%
    \Return{$A[p]$}\;
  }
  \While{\texttt{\upshape{True}}}{%
    $q = \texttt{Randomized-Partition}(A, p, r)$\;
    $k = q - p + 1$\;
    \If{$i == k$}{%
      \Return{$A[q]$}\;
    }
    \ElseIf{$i < k$}{%
      $r = q - 1$\;
    }
    \Else{%
      $p = q + 1$\;
      $i = i - k$\;
    }
  }
}
\end{algorithm}
\end{framed}

\item[9.2-4]{Suppose we use \textsc{Randomized-Select} to select the minimum
element of the array $A = \langle 3, 2, 9, 0, 7, 5, 4, 8, 6, 1 \rangle$.
Describe a sequence of partitions that results in a worst-case performance of
\textsc{Randomized-Select}.}

\begin{framed}
The worst-case occurs when the pivot is always the greatest element. The number
of calls to partition in this case is $n - 1$.
\end{framed}

\end{enumerate}

\newpage

\section{Selection in worst-case linear time}

\begin{enumerate}

\item[9.3-1]{In the algorithm \textsc{Select}, the input elements are divided
into groups of 5. Will the algorithm work in linear time if they are divided
into groups of 7? Argue that \textsc{Select} does not run in linear time if
groups of 3 are used.}

\begin{framed}
If the elements are divided into groups of 7, the number of elements
greater/smaller than the median-of-medians is at least
\[
  7 \left( \Bigl\lceil \frac{1}{2} \Bigl\lceil \frac{n}{7} \Bigr\rceil \Bigr\rceil - 2 \right)
  \ge \frac{4n}{14} - 8 = \frac{2n}{7} - 8,
\]
which implies that, in the worst-case, step 5 calls \textsc{Select} recursively
on at most
\[
  n - \left( \frac{2n}{7} - 8 \right) = \frac{5n}{7} + 8
\]
elements. We then have the recurrence
\[
  T(n) = T\left( \Bigl\lceil \frac{n}{7} \Bigr\rceil \right) + T\left( \frac{5n}{7} + 8 \right) + O(n).
\]

We shall prove that its running time is linear by substitution. More
specifically, we will show that
\[
    T(n) \le cn \; \Forall n \ge n_0,
\]
where $c$ and $n_0$ are positive constants. Substituting into the recurrence,
yields
\begin{equation*}
\begin{aligned}
  T(n) &\le c \Bigl\lceil \frac{n}{7} \Bigr\rceil + c \left( \frac{5n}{7} + 8 \right) + an\\
       &\le c \frac{n}{7} + c + c \frac{5n}{7} + 8c + an & \text{($c \ge 1$)}\\
       &=   \frac{6}{7} cn + 9c + an\\
       &=   cn + \left( - \frac{1}{7} cn + 9c + an \right)\\
       &\le cn,
\end{aligned}
\end{equation*}
where the last step holds for
\[
  -\frac{1}{7} cn + 9c + an \le 0 \rightarrow c \ge 7a \left(\frac{n}{n - 63}\right),
\]
and picking $n_0 = 126$, it holds for $c \ge 14a$.

Similarly, with groups of 3, the number of elements greater/smaller than the
median-of-medians is at least
\[
  2 \left( \Bigl\lceil \frac{1}{2} \Bigl\lceil \frac{n}{3} \Bigr\rceil \Bigr\rceil - 2 \right)
  \ge \frac{n}{3} - 4.
\]
which implies that, in the worst-case, step 5 calls \textsc{Select} recursively
on at most
\[
  n - \left( \frac{n}{3} - 4 \right) = \frac{2n}{3} + 4
\]
elements. We then have the recurrence
\[
  T(n) = T\left( \Bigl\lceil \frac{n}{3} \Bigr\rceil \right) + T\left( \frac{2n}{3} + 4 \right) + O(n).
\]

We shall prove that its running time is $\omega(n)$ by substitution. More
specifically, we will show that
\[
  T(n) > cn + d \; \Forall n \ge n_0,
\]
where $c$, $d$, and $n_0$ are positive constants. Substituting into the
recurrence, yields
\begin{equation*}
\begin{aligned}
  T(n) &> c \Bigl\lceil \frac{n}{3} \Bigr\rceil + d + c \left( \frac{2n}{3} + 4 \right) + d + an\\
       &> c \frac{n}{3} + c + d + c \frac{2n}{3} + 4c + d + an & \text{($c \ge 1$)}\\
       &= cn + 5c + 2d + an\\
       &> cn,\\
\end{aligned}
\end{equation*}
where the last step holds for $5c + 2d + an > 0$.
\end{framed}

\item[9.3-2]{Analyze \textsc{Select} to show that if $n \ge 140$, then at least
$\ceil{n/4}$ elements are greater than the median-of-medians $x$ and at least
$\ceil{n/4}$ elements are less than $x$.}

\begin{framed}
We have that at least
\[
  \frac{3n}{10} - 6
\]
elements are greater/smaller than $x$. To this number be equal to or greater
than $\ceil{n/4}$, we find $n$ such that
\begin{equation*}
\begin{aligned}
  \frac{3n}{10} - 6 \ge \Bigl\lceil \frac{n}{4} \Bigr\rceil
  &\rightarrow \frac{3n}{10} - 6 \ge \frac{n}{4} + 1\\
  &\rightarrow \frac{6n - 5n}{20} \ge 7\\
  &\rightarrow \frac{n}{20} \ge 7\\
  &\rightarrow n \ge 140.
\end{aligned}
\end{equation*}
\end{framed}

\item[9.3-3]{Show how quicksort can be made to run in $O(n \lg n)$ time in the
worst-case, assuming that all elements are distinct.}

\begin{framed}
Update the partition procedure to use the median as the pivot. It will take an
additional $O(n)$-time to find the median with the \textsc{Select} procedure,
but the running time of partition will still be linear. We will then have the
recurrence
\[
  T(n) = 2T \left( \frac{n}{2} \right) + O(n),
\]
which takes
\[
  \sum_{i = 0}^{\lg n} 2^i \cdot \frac{n}{2^i} = \sum_{i = 0}^{\lg n} n = O(n \lg n).
\]
\end{framed}

\item[9.3-4]{($\star$) Suppose that an algorithm uses only comparisons to find
the $i$th smallest element in a set of $n$ elements. Show that it can also find
the $i - 1$ smaller elements and the $n - i$ larger elements without performing
any additional comparisons.}

\begin{framed}
Assume without loss of generality that the elements of the array are distinct.
Let $x$ denote the $i$th order statistic that was found through comparisons.
First note that if there exists an element $y$ that was never compared to any
other element, its value was not taken into account to determine $x$, which
implies that there are at least two possible order statistics for $x$ {--} one
for $y < x$ and another for $y > x$. The same occurs if $y$ is only compared to
elements that are not between $x$ and $y$ in the sorted order. Note that these
comparisons are insufficient to determine if $y$ is smaller or greater than $x$,
and there will also be at least two possible order statistics for $x$.
Therefore, to find $x$, the algorithm must compare $y$ to $x$ directly or by
transitivity. These comparisons are sufficient to determine the relative order
of every element with respect to $x$, and therefore to also determine the
$i - 1$ smaller and the $n - i$ greater elements of the array.
\end{framed}

\newpage

\item[9.3-5]{Suppose that you have a ``black-box'' worst-case linear-time median
subroutine. Give a simple, linear-time algorithm that solves the selection
problem for an arbitrary order statistic.}

\begin{framed}
A simple algorithm works as follows:
\begin{enumerate}
\item Find the lower median $m$ using the ``black-box'' median subroutine.
\item If $i = \ceil{n/2}$, just return $m$. Otherwise, partition the array using
$m$ as the pivot and recursively find the $i$th element on the first
$\ceil{n / 2} - 1$ elements if $i < \ceil{n / 2}$, or the $(i - \ceil{n / 2})$th
element on the last $\floor{n/2}$ elements if $i > \ceil{n/2}$.
\end{enumerate}

This algorithm has the recurrence
\[
  T(n) = T(n/2) + O(n),
\]
which can be solved using case 3 of the master method, since $n^{\lg 1}$ is
polynomially smaller than $f(n)$. Thus, $T(n) = \Theta(n)$.

The pseudocode of this algorithm is stated below.

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Select'}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r, i}}{%
  $m = \texttt{Median}(A, p, r)$\;
  $k = \ceil{n/2}$\;
  \If{$i == k$}{%
    \Return{$m$}\;
  }
  \Else{%
    $q = \texttt{Partition}(A, p, r, m)$\;
    \If{$i < k$}{%
      // recurve over the first $\ceil{n/2} - 1$ elements\;
      $\texttt{Select'}(A, p, p + k - 2, i)$\;
    }
    \Else{%
      // recurve over the last $\floor{n/2}$ elements\;
      $\texttt{Select'}(A, p + k, r, i - k)$\;
    }
  }
}
\end{algorithm}

\end{framed}

\newpage

\item[9.3-6]{The $k$th \textbf{\emph{quantiles}} of an $n$-element set are the
$k - 1$ order statistics that divide the sorted set into $k$ equal-sized sets
(to within 1). Give an $O(n \lg k)$-time algorithm to list the $k$th quantiles
of a set.}

\begin{framed}
Let $S$ be an $n$-set and $S_{(i)}$ denote the $i$th order statistic of $S$. The
$k$th quantiles of $S$ are the elements
\[
  S_{(1 (n / k))}, S_{(2 (n / k))}, \dots, S_{((k - 1) (n / k))}.
\]
An efficient algorithm to find the above elements work as follows:
\begin{enumerate}
\item If $k = 1$, then return $\emptyset$.
\item Otherwise, do the following:
\begin{enumerate}
\item Partition $S$ around the element $S_{(\floor{k / 2} (n / k))}$. Let $q$
denote the position of the pivot after partition and let $S_1$ and $S_2$ denote
the subsets $S[1, \dots, q]$ and $S[q + 1, \dots, n]$, respectively.
\item Recursively solve the $(\floor{k/2})$th quantiles of $S_1$ and the
$(\ceil{k/2})$ quantiles of $S_2$. Let $Q_1$ and $Q_2$ denote the solutions of
$S_1$ and $S_2$, respectively.
\item Return $Q_1 \cup \{S[q]\} \cup Q_2$.
\end{enumerate}
\end{enumerate}

We shall now prove that this algorithm runs in $O(n \lg k)$. First note that
since
\[
  n \text{ mod } k = 0,
\]
$k$ is even implies that $n$ is also even. Thus, for even $k$, we have
\begin{equation*}
\begin{aligned}
  \Bigl\lfloor \frac{k}{2} \Bigr\rfloor \cdot \frac{n}{k}
  &= \frac{k}{2} \cdot \frac{n}{k}\\
  &= \frac{n}{2}\\
  &= \Bigl\lfloor \frac{n}{2} \Bigr\rfloor,
\end{aligned}
\end{equation*}
which implies that $q$ is the lower median. When $k$ is odd, we have
\begin{equation*}
\begin{aligned}
  \Bigl\lfloor \frac{k}{2} \Bigr\rfloor \cdot \frac{n}{k}
  &=   \frac{k - 1}{2} \cdot \frac{n}{k}\\
  &=   \left( \frac{k}{2} - \frac{1}{2} \right) \frac{n}{k}\\
  &=   \frac{n}{2} - \frac{n}{2k}.
\end{aligned}
\end{equation*}
Step (a) takes $O(1)$. Step (b) has the recurrence
\begin{equation*}
T(n, k) =
\begin{cases}
  O(1), & k = 1\\
  T\left( \Bigl\lfloor \frac{n}{2} \Bigr\rfloor, \Bigl\lfloor \frac{k}{2} \Bigr\rfloor \right) +
  T\left( \Bigl\lceil \frac{n}{2} \Bigr\rceil, \Bigl\lceil \frac{k}{2} \Bigr\rceil \right) +
  O(n), & \text{$k > 1$ and $k$ is even}\\
  T\left( \frac{n}{2} - \frac{n}{2k}, \Bigl\lfloor \frac{k}{2} \Bigr\rfloor \right) +
  T\left( \frac{n}{2} + \frac{n}{2k}, \Bigl\lceil \frac{k}{2} \Bigr\rceil \right) +
  O(n), & \text{$k > 1$ and $k$ is odd}
\end{cases}
\end{equation*}

We shall solve this recurrence through the analysis of its recursion-tree. Since
the problem is always divided into two subproblems, without overlap, the total
cost over all nodes at depth $i$ is $cn$. The bottom level at depth $\lg k$
has $2^{\lg k} = k$ nodes, each contributing cost $O(1)$, for a total cost of
$O(k)$. Thus, the cost of the entire tree is \begin{equation*}
\begin{aligned}
  T(n, k) &= \sum_{i = 0}^{\lg k - 1} cn + O(k)\\
          &= cn \lg k + O(k)\\
          &= O(n \lg k).
\end{aligned}
\end{equation*}

\end{framed}

\newpage

\item[9.3-7]{Describe an $O(n)$-time algorithm that, given a set $S$ of $n$
distinct numbers and a positive integer $k \le n$, determines the $k$ numbers in
$S$ that are closest to the median of $S$.}

\begin{framed}
Let $A$ be an array of size $n$. The following algorithm finds $k$ elements of
$A$ such that every element
\begin{itemize}
\item is greater than or equal to the $(\floor{n/2} - \floor{(k - 1)/2})$th
  order statistic of $A$, and
\item is lower than or equal to the $(\floor{n/2} + \ceil{(k - 1)/2})$th order
  statistic of $A$.
\end{itemize}

Do the following steps:
\begin{enumerate}
\item Find the $q$th order statistic of $A$, such that
$q = \floor{n/2} - \floor{(k - 1)/2}$, and partition $A$ around this element.
\item If $k = 1$, return $A[q]$.
\item Otherwise, do the following:
\begin{enumerate}
\item Let $A'$ denote subarray $A[q, \dots, n]$.
\item Find the $k$th order statistic of $A'$ and partition $A'$ around this
element.
\item Return the subarray $A'[q, \dots, q + k - 1]$.
\end{enumerate}
\end{enumerate}

The algorithm do at most two selections and two partitions. Thus, its running
time is $4 \cdot O(n) + O(1) = O(n)$.
\end{framed}

\item[9.3-8]{Let $X[1 \dots n]$ and $Y[1 \dots n]$ be two arrays, each
containing $n$ numbers already in sorted order. Give an $O(\lg n)$-time algorithm
to find the median of all $2n$ elements in arrays $X$ and $Y$.}

\begin{framed}
Note that, since both arrays are sorted, the order statistic of $X[i]$ is
$\floor{(n + 1)/2}$ (the median) if, and only if,
\[
  X[i] \ge Y\left[ \Bigl\lfloor \frac{n + 1}{2} \Bigr\rfloor - i \right],
\]
and
\[
  X[i] \le Y\left[ \Bigl\lfloor \frac{n + 1}{2} \Bigr\rfloor - i + 1 \right].
\]

Start testing the median of $X$. If the first comparison fails, recurse over the
right half. If the second comparison fails, recurse over the left half.
Otherwise, return $X[i]$. If a recursion is performed on an empty array, the
median is not within $X$. Repeat a similar procedure on $Y$ to find the median.
The complexity of this algorithm is $O(\lg n) + O(\lg n) = O(\lg n)$.
\end{framed}

\item[9.3-9]{Professor Olay is consulting for an oil company, which is planning
a large pipeline running east to west through an oil field of $n$ wells. The
company wants to connect a spur pipeline from each well directly to the main
pipeline along a shortest route (either north or south), as shown in Figure 9.2.
Given the $x$- and $y$-coordinates of the wells, how should the professor pick
the optimal location of the main pipeline, which would be the one that minimizes
the total length of the spurs? Show how to determine the optimal location in
linear time.}

\begin{framed}
The optimal locations are the lower and upper medians of the $y$ values. Find
one of them with the \textsc{Select} algorithm.
\end{framed}

\end{enumerate}

\newpage

\section*{Problems}
\addcontentsline{toc}{section}{\protect\numberline{}Problems}%

\begin{enumerate}

\item[9-1]{\textbf{\emph{Largest i numbers in sorted order}}\\
Given a set of $n$ numbers, we wish to find the $i$ largest in sorted order
using a comparison-based algorithm. Find the algorithm that implements each of
the following methods with the best asymptotic worst-case running time, and
analyze the running times of the algorithms in terms of $n$ and $i$.

\begin{enumerate}
  \item[\textbf{a.}] Sort the numbers, and list the $i$ largest.
  \item[\textbf{b.}] Build a max-priority queue from the numbers, and call \textsc{Extract-Max} $i$ times.
  \item[\textbf{c.}] Use an order-statistic algorithm to find the $i$th largest number,
    partition around that number, and sort the $i$ largest numbers.
\end{enumerate}
}

\begin{framed}
\begin{enumerate}
\item The pseudocode is stated below.

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{LargestNumbersSort}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, i}}{%
  Let $B$ be an integer array of size $i$\;
  \texttt{Heapsort}($A, 1, A.length$)\;
  \For{$j = 1$ \KwTo $i$}{%
    $B[j] = A[j]$\;
  }
  \Return{$B$}\;
}
\end{algorithm}

    This algorithm runs in $\Theta(n \lg n + i) = \Theta(n \lg n)$.

\item The pseudocode is stated below.

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{LargestNumbersPriorityQueue}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, i}}{%
  Let $B$ be an integer array of size $i$\;
  \texttt{Build-Max-Heap}($A$)\;
  \For{$j = 1$ \KwTo $i$}{%
    $\text{\emph{element}}$ = \texttt{Heap-Extract-Max}($A$)\;
    $B[i - j + 1] = element$\;
  }
  \Return{$B$}\;
}
\end{algorithm}

\textsc{Build-Max-Heap} call takes $O(n)$, \textsc{Extract-Max} call takes
$O(\lg n)$. This algorithm runs in $O(n + i \lg n)$.

\item The pseudocode is stated below.

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{LargestNumbersOrderStatistic}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, i}}{%
  Let $B$ be an integer array of size $i$\;
  $q = \texttt{Select}(A, i)$\;
  \texttt{Partition}($A, 1, A.length, q$)\;
  \texttt{Heapsort}($A, 1, i$)\;
  \For{$j = 1$ \KwTo $i$}{%
    $B[j] = A[j]$\;
  }
  \Return{$B$}\;
}
\end{algorithm}

\textsc{Select} call takes $O(n)$, \textsc{Partition} call takes $O(n)$,
\textsc{Quicksort} call takes $O(i \lg i)$. This algorithm runs in $O(n + i \lg i)$.
\end{enumerate}
\end{framed}

\newpage

\item[9-2]{\textbf{\emph{Weighted median}}\\
For $n$ distinct elements $x_1, x_2, \dots, x_n$ with positive weights
$w_1, w_2, \dots, w_n$ such that $\sum_{i = 1}^{n} w_i = 1$, the
\textbf{\emph{weighted (lower) median}} is the element $x_k$ satisfying
\[
  \sum_{x_i < x_k} w_i < \frac{1}{2},
\]
and
\[
  \sum_{x_i > x_k} w_i \le \frac{1}{2}.
\]

For example, if the elements are 0.1, 0.35, 0.05, 0.1, 0.15, 0.05, 0.2 and each
element equals its weight (that is, $w_i = x$ for $i = 1, 2, \dots, 7$), the
median is 0.1, but the weighted median is 0.2.

\begin{enumerate}
\item[\textbf{a.}] Argue that the median of $x_1, x_2, \dots, x_n$ is the
weighted median of the $x_i$ with weights $w_i = 1/n$ for $1, 2, \dots, n$.
\item[\textbf{b.}] Show how to compute the weighted median of $n$ elements in
$O(n \lg n)$ worst-case time using sorting.
\item[\textbf{c.}] Show how to compute the weighted median in $\Theta(n)$
worst-case time using a linear-time median algorithm such as \textsc{Select}
from Section 9.3.
\end{enumerate}

The \textbf{\emph{post-office location problem}} is defined as follows. We are
given $n$ points $p_1, p_2, \dots, p_n$ with associated weights
$w_1, w_2, \dots, w_n$. We wish to find a point $p$ (not necessarily one of the
input points) that minimizes the sum $\sum_{i = 1}^n w_i d(p, p_i)$, where
$d(a, b)$ is the distance between points $a$ and $b$.

\begin{enumerate}
\item[\textbf{d.}] Argue that the weighted median is a best solution for the
1-dimensional post-office location problem, in which points are simply real
numbers and the distance between points $a$ and $b$ is $d(a, b) = |a - b|$.

\item[\textbf{e.}] Find the best solution for the 2-dimensional post-office
location problem, in which the points are $(x, y)$ coordinate pairs and the
distance between points $a = (x_1, y_1)$ and $b = (x_2, y_2)$ is the
\textbf{\emph{Manhattan distance}} given by
$d(a, b) = |x_1 - x_2| + |y_1 - y_2|$.
\end{enumerate}
}

\begin{framed}
\begin{enumerate}
\item Note that there are at most $\floor{(n - 1)/2}$ elements that are smaller
than the median and at most $\ceil{(n - 1)/2}$ elements that are greater than
the median. Since the weight of each element is $1/n$, we have
\[
  \sum_{x_i < x_k} w_i = \sum_{x_i < x_k} \frac{1}{n}
    = \frac{1}{n} \sum_{x_i < x_k} 1
    \le \frac{1}{n} \cdot \Bigl\lfloor \frac{n - 1}{2} \Bigr\rfloor
    < \frac{1}{n} \cdot \frac{n}{2} = \frac{1}{2},
\]
and
\[
  \sum_{x_i < x_k} w_i = \sum_{x_i < x_k} \frac{1}{n}
  = \frac{1}{n} \sum_{x_i < x_k} 1
  \le \frac{1}{n} \cdot \Bigl\lceil \frac{n - 1}{2} \Bigr\rceil
  \le \frac{1}{n} \cdot \frac{n}{2} = \frac{1}{2},
\]
which implies that the median is also the weighted median.

\item Sort the array with \textsc{Heapsort}. Iterate over the elements of the
array, accumulating the sum of their weights until the sum achieves a value that
is greater than or equal to $1/2$. Let $x_k$ denote the last element that made
the sum accumulate a value greater than or equal to $1/2$. Note that at that
point
\[
  \sum_{x_i < x_k} w_i < \frac{1}{2}
\]
holds since the sum of the weights until the element right before $x_k$ is
smaller than $1/2$ and
\[
  \sum_{x_i > x_k} w_i \le \frac{1}{2}
\]
holds since the sum of the weights until $x_k$ is greater than or equal to $1/2$
and $\sum_{i = 1}^{n} w_i = 1$. Thus, $x_k$ is the weighted median. This
algorithm takes $\Theta(n \lg n)$ to sort the array with \textsc{Heapsort} and
$O(n)$ to accumulate the weights and find the weighted median.

\item Do the following steps:
\begin{enumerate}
\item Find the median with the \textsc{Select} algorithm.
\item Partition the array around the median.
\item Let $x_m$ denote the position of the median after partitioning. Let
$W_L = \sum_{X_i < X_m} w_i$ and $W_R = \sum_{x_i > x_m} w_i$.
\item If $W_L < 1/2$ and $W_R \le 1/2$, $x_m$ is the weighted median. Otherwise,
do the following:
\begin{enumerate}
\item If $W_L \ge 1/2$, the weighted median is before $x_m$.
Set $w_m = w_m + W_R$ and recurse on the left half of the array, including
$x_m$.
\item If $W_R > 1/2$, the weighted median is after $x_m$. Set $w_m = w_m + W_L$
and recurse on the right half of the array, including $x_m$.
\end{enumerate}
\end{enumerate}

This algorithm has the recurrence:
\[
  T(n) = T\left(\frac{n}{n} + 1\right) + \Theta(n)
       = \sum_{i = 0}^{\lg n} \left(\frac{n}{2^i} + 1\right)
       = n \sum_{i = 0}^{\lg n} \frac{1}{2^i} + \sum_{i = 0}^{\lg n} 1
       \le 2n + \lg n + 1
       = \Theta(n).
\]

\item Skipped.

\item Skipped.

\end{enumerate}
\end{framed}

\newpage

\item[9-3]{\textbf{\emph{Small order statistics}}\\
We showed that the worst-case number $T(n)$ of comparisons used by
\textsc{Select} to select the ith order statistic from $n$ numbers satisfies
$T(n) = \Theta(n)$, but the constant hidden by the $\Theta$-notation is rather
large. When $i$ is small relative to $n$, we can implement a different procedure
that uses \textsc{Select} as a subroutine but makes fewer comparisons in the
worst case.

\begin{enumerate}
\item[\textbf{a.}] Describe an algorithm that uses $U_i(n)$ comparisons to
find the $i$th smallest of $n$ elements, where
\[
U_i(n) =
\begin{cases}
  T(n) & \text{if } i \ge n/2,\\
  \floor{n/2} + U_i(\ceil{n/2}) + T(2i) & \text{otherwise}.
\end{cases}
\]

(\emph{Hint:} Begin with $\floor{n/2}$ disjoint pairwise comparisons, and
recurse on the set containing the smaller element from each pair.)

\item[\textbf{b.}] Show that, if $i < n/2$, then $U_i(n) = n + O(T(2i) \lg (n/i))$.

\item[\textbf{c.}] Show that if $i$ is a constant less than $n/2$, then $U_i(n) = n + O(\lg n)$.

\item[\textbf{d.}] Show that if $i = n/k$ for $k \ge 2$, then $U_i(n) = n + O(T(2n/k) \lg k)$.
\end{enumerate}
}

\begin{framed}
\begin{enumerate}
\item First, note that the \textsc{Select} algorithm find the $i$th element by
partitioning the array. That is, when the $i$th element is found, the first $i$
elements are the $i$ smallest. However, when $n$ is too large with respect to
$i$, it perform more comparisons than necessary. Taking the hint that the
question gave us, we can reduce the number of comparisons when $n$ is too large
by running \textsc{Select} only when $n$ is smaller than or equal to $2i$.

The key insight to solve the question is to observe that if we first make
disjoint pairwise comparisons and then run \textsc{Select} only among the
smallest element of each pair, the $i$th order statistic of the whole array is
among the $i$ smallest elements that were found by \textsc{Select} and their
large counterparts on the right half of the array. This occurs because the
remaining elements on the left half are larger than at least $i$ elements and
their larger counterparts on the right half are even larger.

We can then use this notion to build a recursive algorithm that solves the
selection problem with fewer comparisons, using the \textsc{Select} algorithm
only when $n$ is small enough:
\begin{enumerate}
  \item If $i \ge n/2$, run \textsc{Select} and return its result.
  \item Otherwise, do the following:
  \begin{enumerate}
    \item Perform disjoint pairwise comparisons and rearrange the array such
      that the smaller element of each pair appears on the left half of the
      array, in the same order of its larger counterparts.
    \item Recursively find the $i$th element among the elements on the left half
      of the array.
    \item The $i$th order statistic is among the first $i$ elements of the array
      and their larger counterparts. Run \textsc{Select} on these $2i$ elements
      and return the result.
  \end{enumerate}
\end{enumerate}

\item Can be proved by substitution.

\item From the previous item, we have
\[
  U_i(n) = n + O(T(2i) \lg(n/i)),
\]

which implies that, when $i$ is a constant less than $n/2$, we have
\begin{equation*}
\begin{aligned}
  U_i(n) &= n + O(T(2i) \lg(n/i))\\
         &= n + O(O(1) O(\lg n))\\
         &= n + O(\lg n).
\end{aligned}
\end{equation*}

\item If $k > 2$, then $i < n/2$ and we can use the result of item (b):
\begin{equation*}
\begin{aligned}
  U_i(n) &= n + O(T(2i)\lg(n/i))\\
         &= n = O(T(2n/k) \lg(n/(n/k)))\\
         &= n = O(T(2n/k) \lg(k)).
\end{aligned}
\end{equation*}

If $k = 2$, then $i = n/2$ and $\lg k = 1$. Thus, we have
\begin{equation*}
\begin{aligned}
  U_i(n) &=   T(n)\\
         &\le n + T(n) + \lg k\\
         &=   n + O(T(n) + \lg k)\\
         &=   n + O(T(2n/k) + \lg k).
\end{aligned}
\end{equation*}

\end{enumerate}
\end{framed}

\newpage

\item[9-4]{\textbf{\emph{Alternative analysis of randomized selection}}\\
In this problem, we use indicator random variables to analyze the
\textsc{Randomized-Select} procedure in a manner akin to our analysis of
\textsc{Randomized-Quicksort} in Section 7.4.2.

As in the quicksort analysis, we assume that all elements are distinct, and we
rename the elements of the input array $A$ as $z_1, z_2, \dots, z_n$, where
$z_i$ is the $i$th smallest element. Thus, the call
\textsc{Randomized-Select}($A, 1, n, k$) returns $z_k$.

For $1 \le i < j \le n$, let $X_{ijk}$ = I\{$z_i$ is compared with $z_j$
sometime during the execution of the algorithm to find $z_k$\}.

\begin{enumerate}
\item[\textbf{a.}] Give an exact expression for $\text{E}[X_{ijk}]$.
(\emph{Hint:} Your expression may have different values, depending on the values
of $i, j,$ and $k$.)

\item[\textbf{b.}] Let $X_k$ denote the total number of comparisons between
elements of array $A$ when finding $z_k$. Show that
\[
  \text{E}[X_k] \le 2 \left( \sum_{i = 1}^{k} \sum_{j = k}^{n} \frac{1}{j - i + 1} +
                             \sum_{j = k + 1}^{n} \frac{j - k - 1}{j - k + 1} +
                             \sum_{i = 1}^{k - 2} \frac{k - i - 1}{k - i + 1} \right).
\]

\item[\textbf{c.}] Show that $\text{E}[X_k] \le 4n$.

\item[\textbf{d.}] Conclude that, assuming all elements of array $A$ are
distinct, \textsc{Randomized-Select} runs in expected time $O(n)$.
\end{enumerate}
}

\begin{framed}
Skipped.
\end{framed}

\end{enumerate}
