\documentclass{report}

%                       MAIN PACKAGES                       %
% --------------------------------------------------------- %

\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{isolatin1}
\usepackage{amssymb}
\usepackage{textcomp}
\usepackage[usenames,dvipsnames]{color}
\usepackage{soul}
\usepackage{cancel}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{framed}
\usepackage{xcolor}
\usepackage{algpseudocode}
\usepackage[linesnumbered]{algorithm2e} % for psuedo code
\usepackage{courier}
\usepackage{mathtools} % loads amsmath
\usepackage{forest}
\usepackage{tikz}
\usepackage{tikz-qtree}
\usepackage{interval}
\usetikzlibrary{calc}

%                         MARGINS                           %
% --------------------------------------------------------- %

\hoffset=-0.5in
\voffset=-0.6in
\oddsidemargin=0pt
\topmargin=0pt
\headheight=12pt
\headsep=15pt
\textheight=690pt
\textwidth=543pt
\marginparsep=11pt
\marginparwidth=54pt
\footskip=25pt
\marginparpush=5pt
\paperwidth=597pt
\paperheight=845pt

%                        PAGE STYLE                         %
% --------------------------------------------------------- %

\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{CLRS {--} Chapter 7 {--} Quicksort}
\rhead{Daniel Bastos Moraes}
\cfoot{}
\rfoot{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\newcommand{\Perp}{\perp\! \! \! \perp}

%                       PROPERTIES                          %
% --------------------------------------------------------- %

\setlength{\parindent}{0cm}

\makeatletter
\renewenvironment{framed}{%
 \def\FrameCommand##1{\hskip\@totalleftmargin
 \fboxsep=\FrameSep\fbox{##1}}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed}
\makeatother

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\DeclareMathOperator{\Exists}{\exists}
\DeclareMathOperator{\Forall}{\forall}

\def\figuredirectory{images}

\mathchardef\mhyphen="2D % Define a "math hyphen"

\tikzset{every tree node/.style={minimum width=1.95em,draw,circle,font=\footnotesize},
         blank/.style={draw=none},
         edge from parent/.style=
         {draw, edge from parent path={(\tikzparentnode) -- (\tikzchildnode)}},
         level distance=1cm}

\DeclareMathOperator{\di}{d\!}
\newcommand*\Eval[3]{\left.#1\right\rvert_{#2}^{#3}}

\intervalconfig{soft open fences}

\let\oldnl\nl% Store \nl in \oldnl
\newcommand{\nonl}{\renewcommand{\nl}{\let\nl\oldnl}}% Remove line number for one line

%                        DOCUMENT                           %
% --------------------------------------------------------- %

\begin{document}

\small

{\large Section 7.1 {--} Description of quicksort}

\begin{enumerate}

\item[7.1{-}1]{Using Figure 7.1 as a model, illustrate the operation of
\textsc{Partition} on the array
$A = \langle 13, 19, 9, 5, 12, 8, 7, 4, 21, 2, 6, 11 \rangle$.}

\begin{framed}
{\centering $ \displaystyle
\definecolor{l}{gray}{0.9}
\definecolor{d}{gray}{0.8}
\definecolor{w}{HTML}{FFFFFF}
\begin{aligned}
  \colorbox{w}{\makebox[1em]{13}} \colorbox{w}{\makebox[1em]{19}} \colorbox{w}{\makebox[1em]{9}}
  \colorbox{w}{\makebox[1em]{5}}  \colorbox{w}{\makebox[1em]{12}} \colorbox{w}{\makebox[1em]{8}}
  \colorbox{w}{\makebox[1em]{7}}  \colorbox{w}{\makebox[1em]{4}}  \colorbox{w}{\makebox[1em]{21}}
  \colorbox{w}{\makebox[1em]{2}}  \colorbox{w}{\makebox[1em]{6}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}\\
%
  \colorbox{d}{\makebox[1em]{13}} \colorbox{w}{\makebox[1em]{19}} \colorbox{w}{\makebox[1em]{9}}
  \colorbox{w}{\makebox[1em]{5}}  \colorbox{w}{\makebox[1em]{12}} \colorbox{w}{\makebox[1em]{8}}
  \colorbox{w}{\makebox[1em]{7}}  \colorbox{w}{\makebox[1em]{4}}  \colorbox{w}{\makebox[1em]{21}}
  \colorbox{w}{\makebox[1em]{2}}  \colorbox{w}{\makebox[1em]{6}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}\\
%
  \colorbox{d}{\makebox[1em]{13}} \colorbox{d}{\makebox[1em]{19}} \colorbox{w}{\makebox[1em]{9}}
  \colorbox{w}{\makebox[1em]{5}}  \colorbox{w}{\makebox[1em]{12}} \colorbox{w}{\makebox[1em]{8}}
  \colorbox{w}{\makebox[1em]{7}}  \colorbox{w}{\makebox[1em]{4}}  \colorbox{w}{\makebox[1em]{21}}
  \colorbox{w}{\makebox[1em]{2}}  \colorbox{w}{\makebox[1em]{6}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}\\
%
  \colorbox{l}{\makebox[1em]{9}} \colorbox{d}{\makebox[1em]{19}} \colorbox{d}{\makebox[1em]{13}}
  \colorbox{w}{\makebox[1em]{5}} \colorbox{w}{\makebox[1em]{12}} \colorbox{w}{\makebox[1em]{8}}
  \colorbox{w}{\makebox[1em]{7}} \colorbox{w}{\makebox[1em]{4}}  \colorbox{w}{\makebox[1em]{21}}
  \colorbox{w}{\makebox[1em]{2}} \colorbox{w}{\makebox[1em]{6}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}\\
%
  \colorbox{l}{\makebox[1em]{9}}  \colorbox{l}{\makebox[1em]{5}}  \colorbox{d}{\makebox[1em]{13}}
  \colorbox{d}{\makebox[1em]{19}} \colorbox{w}{\makebox[1em]{12}} \colorbox{w}{\makebox[1em]{8}}
  \colorbox{w}{\makebox[1em]{7}}  \colorbox{w}{\makebox[1em]{4}}  \colorbox{w}{\makebox[1em]{21}}
  \colorbox{w}{\makebox[1em]{2}}  \colorbox{w}{\makebox[1em]{6}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}\\
%
  \colorbox{l}{\makebox[1em]{9}}  \colorbox{l}{\makebox[1em]{5}}  \colorbox{d}{\makebox[1em]{13}}
  \colorbox{d}{\makebox[1em]{19}} \colorbox{d}{\makebox[1em]{12}} \colorbox{w}{\makebox[1em]{8}}
  \colorbox{w}{\makebox[1em]{7}}  \colorbox{w}{\makebox[1em]{4}}  \colorbox{w}{\makebox[1em]{21}}
  \colorbox{w}{\makebox[1em]{2}}  \colorbox{w}{\makebox[1em]{6}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}\\
%
  \colorbox{l}{\makebox[1em]{9}}  \colorbox{l}{\makebox[1em]{5}}  \colorbox{l}{\makebox[1em]{8}}
  \colorbox{d}{\makebox[1em]{19}} \colorbox{d}{\makebox[1em]{12}} \colorbox{d}{\makebox[1em]{13}}
  \colorbox{w}{\makebox[1em]{7}}  \colorbox{w}{\makebox[1em]{4}}  \colorbox{w}{\makebox[1em]{21}}
  \colorbox{w}{\makebox[1em]{2}}  \colorbox{w}{\makebox[1em]{6}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}\\
%
  \colorbox{l}{\makebox[1em]{9}}  \colorbox{l}{\makebox[1em]{5}}  \colorbox{l}{\makebox[1em]{8}}
  \colorbox{l}{\makebox[1em]{7}}  \colorbox{d}{\makebox[1em]{12}} \colorbox{d}{\makebox[1em]{13}}
  \colorbox{d}{\makebox[1em]{19}} \colorbox{w}{\makebox[1em]{4}}  \colorbox{w}{\makebox[1em]{21}}
  \colorbox{w}{\makebox[1em]{2}}  \colorbox{w}{\makebox[1em]{6}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}\\
%
  \colorbox{l}{\makebox[1em]{9}}  \colorbox{l}{\makebox[1em]{5}}  \colorbox{l}{\makebox[1em]{8}}
  \colorbox{l}{\makebox[1em]{7}}  \colorbox{l}{\makebox[1em]{4}}  \colorbox{d}{\makebox[1em]{13}}
  \colorbox{d}{\makebox[1em]{19}} \colorbox{d}{\makebox[1em]{12}} \colorbox{w}{\makebox[1em]{21}}
  \colorbox{w}{\makebox[1em]{2}}  \colorbox{w}{\makebox[1em]{6}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}\\
%
  \colorbox{l}{\makebox[1em]{9}}  \colorbox{l}{\makebox[1em]{5}}  \colorbox{l}{\makebox[1em]{8}}
  \colorbox{l}{\makebox[1em]{7}}  \colorbox{l}{\makebox[1em]{4}}  \colorbox{d}{\makebox[1em]{13}}
  \colorbox{d}{\makebox[1em]{19}} \colorbox{d}{\makebox[1em]{12}} \colorbox{d}{\makebox[1em]{21}}
  \colorbox{w}{\makebox[1em]{2}}  \colorbox{w}{\makebox[1em]{6}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}\\
%
  \colorbox{l}{\makebox[1em]{9}}  \colorbox{l}{\makebox[1em]{5}}  \colorbox{l}{\makebox[1em]{8}}
  \colorbox{l}{\makebox[1em]{7}}  \colorbox{l}{\makebox[1em]{4}}  \colorbox{l}{\makebox[1em]{2}}
  \colorbox{d}{\makebox[1em]{19}} \colorbox{d}{\makebox[1em]{12}} \colorbox{d}{\makebox[1em]{21}}
  \colorbox{d}{\makebox[1em]{13}} \colorbox{w}{\makebox[1em]{6}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}\\
%
  \colorbox{l}{\makebox[1em]{9}}  \colorbox{l}{\makebox[1em]{5}}  \colorbox{l}{\makebox[1em]{8}}
  \colorbox{l}{\makebox[1em]{7}}  \colorbox{l}{\makebox[1em]{4}}  \colorbox{l}{\makebox[1em]{2}}
  \colorbox{l}{\makebox[1em]{6}}  \colorbox{d}{\makebox[1em]{12}} \colorbox{d}{\makebox[1em]{21}}
  \colorbox{d}{\makebox[1em]{13}} \colorbox{d}{\makebox[1em]{19}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}\\
%
  \colorbox{l}{\makebox[1em]{9}}  \colorbox{l}{\makebox[1em]{5}}  \colorbox{l}{\makebox[1em]{8}}
  \colorbox{l}{\makebox[1em]{7}}  \colorbox{l}{\makebox[1em]{4}}  \colorbox{l}{\makebox[1em]{2}}
  \colorbox{l}{\makebox[1em]{6}}
  \colorbox{w}{\makebox[1em]{\textcolor{red}{11}}}
  \colorbox{d}{\makebox[1em]{21}} \colorbox{d}{\makebox[1em]{13}} \colorbox{d}{\makebox[1em]{19}}
  \colorbox{d}{\makebox[1em]{12}}\\
\end{aligned} $ \par} % Necessary for centering to work
\end{framed}

\item[7.1{-}2]{What value of $q$ does \textsc{Partition} return when all
elements in the array $A=[p, \dots, r]$ have the same value? Modify
\textsc{Partition} so that $q = \floor{(p + r) / 2}$ when all elements in the
array $A[p, \dots, r]$ have the same value.}

\begin{framed}
It will return $q = r$. We can update \textsc{Partition} to split elements that
are equal to the pivot on both sides as follows:
\begin{enumerate}
\item Count the number of elements $y$ such that $y = x$ and set this value to $c$;
\item Subtract the final pivot index by $\floor{c/2}$.
\end{enumerate}

The updated pseucode is stated below.

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Partition-Improved}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r}}{%
 $x = A[r]$\;
 $i = j = p - 1$\;
 \For{$k = p$ \KwTo $r - 1$}{%
   \If{$A[k] \le x$}{%
     $j = j + 1$\;
     exchange $A[j]$ with $A[k]$\;
     \If{$A[j] < x$}{%
       $i = i + 1$\;
       exchange $A[i]$ with $A[j]$\;
     }
   }
 }
 exchange $A[j + 1]$ with $A[r]$\;
 $q = \Bigl\lfloor\frac{(i + 1) + (j + 1)}{2}\Bigr\rfloor$\;
\Return{$q$}\; }
\end{algorithm}
\end{framed}

\item[7.1{-}3]{Give a brief argument that the running time of \textsc{Partition}
on a subarray of size $n$ if $\Theta(n)$.}

\begin{framed}
The \textbf{for} loop of lines $3{-}6$ iterates $n - 1$ times and each
iteration does a constant amount of work. Thus, it is $O(n)$.
\end{framed}

\item[7.1{-}4]{How would you modify \textsc{Quicksort} to sort into
nonincreasing order?}

\begin{framed}
We just need to update the condition
\[
  A[j] \le x,
\]
to
\[
  A[j] \ge x.
\]
\end{framed}

\end{enumerate}

\newpage

{\large Section 7.2 {--} Performance of quicksort}

\begin{enumerate}

\item[7.2{-}1]{Use the substitution method to prove the recurrence
$T(n) = T(n - 1) + \Theta(n)$ has the solution $T(n) = \Theta(n^2)$, as claimed
at the beginning of Section 7.2.}

\begin{framed}
Our guess is
\[
  T(n) \le cn^2 - dn\;\Forall n \ge n_0,
\]
where $c$, $d$, and $n_0$ are positive constants. Substituting into the
recurrence, yields
\begin{equation*}
\begin{aligned}
  T(n) &\le c(n - 1)^2 - d(n - 1) + en\\
       &= cn^2 - 2cn + c -d(n - 1) + en & \text{($c = 1, d = 2e$)}\\
       &\le cn^2,\\
\end{aligned}
\end{equation*}
where the last step holds as long as $n_0 \ge 2$.
\end{framed}

\item[7.2{-}2]{What is the running time of \textsc{Quicksort} when all elements
of array $A$ have the same value?}

\begin{framed}
As discussed in (7.1-2), when all elements are the same, $q$ will always be
equal to $r$, which gives the worst-case split. Thus, \textsc{Quicksort} as
implemented in Section 7.1, will run in $\Theta(n^2)$ in this case.
\end{framed}

\item[7.2{-}3]{Show that the running time of \textsc{Quicksort} is $\Theta(n^2)$
when the array $A$ contains distinct elements and is sorted in decreasing
order.}

\begin{framed}
The pivot index $q$ will always be $1$, which gives a $0$ to $n - 1$ split.
The recurrence will be $T(n) = T(n - 1) + \Theta(n) = \Theta(n^2)$.
\end{framed}

\item[7.2{-}4]{Banks often record transactions on an account in order of the
times of the transactions, but many people like to receive their bank statements
with checks listed in order by check number. People usually write checks in
order by check number, and merchants usually cash them with reasonable dispatch.
The problem of converting time-of-transaction ordering to check-number ordering
is therefore the problem of sorting almost-sorted input. Argue that the
procedure \textsc{Insertion-Sort} would tend to beat the procedure
\textsc{Quicksort} on this problem.}

\begin{framed}
Lets assume that each item is out of order by no more than $k$ positions. Note
that in the above scenario, $k$ usually can be bounded by a constant. In this
case, \textsc{Insertion-Sort} runs in $O(kn)$ (it will make at most $k$ swaps
for each item of the array), which is close to linear for small $k$. On the
other hand, \emph{most} splits given by the \textsc{Partition} procedure will
be no better than a $k - 1$ to $n - k$ split. Assuming that it always give an
$k - 1$ to $n - k$ split, the recurrence of \textsc{Quicksort} will be
$T(n) = T(k) + T(n - k) + \Theta(n)$, which is close to quadratic for small $k$.
\end{framed}

\item[7.2{-}5]{Suppose that the splits at every level of quicksort are in the
proportion $1 - \alpha$ to $\alpha$, where $0 < \alpha \le 1/2$ is a constant.
Show that the minimum depth of a leaf in the recursion tree is approximately
$- \lg n / \lg \alpha$ and the maximum depth is approximately
$- \lg n / \lg (1 - \alpha)$. (Don't worry about integer round-off.)}

\begin{framed}
Note that
\[
  \alpha \le \frac{1}{2} \le 1 - \alpha,
\]
which implies $\alpha n \le (1 - \alpha) n$. Thus, the minimum depth occurs on
the path from which the problem size is always divided by $1/\alpha$. This depth
is the number of divisions of $n$ by
$(1/\alpha)$ until reaching a value less than of equal to one, which is
\[
  \log_{1/\alpha} n = \frac{\lg n}{\lg (1/\alpha)}
                    = \frac{\lg n}{- \lg \alpha}
                    = - \frac{\lg n}{\lg \alpha}.
\]

The maximum depth occurs on the path from which the problem size is always
divided by $1/(1 - \alpha)$. This depth is the number of divisions of $n$ by
$1/(1 - \alpha)$ until reaching a value less than or equal to one, which is
\[
  \log_{1/(1 - \alpha)} n
  = \frac{\lg n}{\lg (1/(1 - \alpha))}
  = \frac{\lg n}{- \lg (1 - \alpha)} = - \frac{\lg n}{\lg (1 - \alpha)}.
\]

\end{framed}

\newpage

\item[7.2{-}6]{($\star$) Argue that for any constant $0 < \alpha \le 1/2$, the
probability is approximately $1 - 2\alpha$ that on a random input array,
\textsc{Partition} produces a split more balanced than $1 - \alpha$ to $\alpha$.}

\begin{framed}
Note that $\alpha$ denotes the proportion of the smallest split. Since the input
array is random, the possible proportions for the smallest split forms a uniform
probability distribution, such that
\[
  \text{Pr}\left\{\left[0, \frac{1}{2}\right]\right\} = 1.
\]

Thus, the probability of getting a more balanced split is
\begin{equation*}
\begin{aligned}
  \text{Pr}\left\{\interval[open left, scaled]{\alpha}{\frac{1}{2}}\right\}
  &= \text{Pr}\left\{\interval[scaled]{\alpha}{\frac{1}{2}}\right\}\\
  &= \frac{1/2 - \alpha}{1/2 - 0}\\
  &= \frac{1/2}{1/2} - \frac{\alpha}{1/2}\\
  &= 1 - 2 \alpha.
\end{aligned}
\end{equation*}
\end{framed}

\end{enumerate}

\newpage

{\large Section 7.3 {--} A randomized version of quicksort}

\begin{enumerate}

\item[7.3{-}1]{Why do we analyze the expected running time of a randomized
algorithm and not its worst-case running time?}

\begin{framed}
We can analyze the worst-case. However, due to the randomization, it is not very
useful since we can not associate a specific input to a specific running time.
On the other hand, we can calculate the expected running time, which takes into
account all the possible inputs.
\end{framed}

\item[7.3{-}2]{When \textsc{Randomized-Quicksort} runs, how many calls are made
to the random-number generator \textsc{Random} in the worst case? How about in the
best case? Give your answer in terms of $\Theta$-notation.}

\begin{framed}
First note that counting the number of calls to \textsc{Random} is the same as
counting number of calls to \textsc{Partition}.

The worst-case occurs when \textsc{Partition} always gives an $(n - 1)$-to-0
split. Note that after the first $n - 1$ pivots are selected, the remaining
subarray will contain a single element. Since \textsc{Partition} is only called
on subarrays of size greater than one, in the worst-case the number of calls to
\textsc{Partition} is $n - 1 = \Theta(n)$.

As for the best case, consider the array $A = [1, 2, 3]$. If the element $2$ is
the first to be selected as a pivot, the subarrays $[1]$ and $[3]$ will not be
passed to \textsc{Partition} (both of them has size one) and the number of calls
to \textsc{Partition} in this case is 1. In general, in the best-case the number
of calls to \textsc{Partition} is $\floor{n/2} = \Theta(n)$.
\end{framed}

\end{enumerate}

\newpage

{\large Section 7.4 {--} Analysis of quicksort}

\begin{enumerate}

\item[7.4{-}1]{Show that in the recurrence
\[
  T(n) = \max_{0 \le q \le n - 1}(T(q) + T(n - q - 1)) + \Theta(n),
\]
\[
  T(n) = \Omega(n^2).
\]}

\begin{framed}
We guess that $T(n) \ge cn^2$ for some constant $c$. Substituting into the
recurrence, yields
\begin{equation*}
\begin{aligned}
  T(n) &\ge \max_{0 \le q \le n - 1}(cq^2 + c(n - q - 1)^2) + \Theta(n)\\
       &=   c \cdot \max_{0 \le q \le n - 1}(q^2 + (n - q - 1)^2) + \Theta(n).
\end{aligned}
\end{equation*}

The expression $q^2 + (n - q - 1)^2$ achieves a maximum at $q = 0$ (proof on
(7.4-3)). Thus, we have
\[
  \max_{0 \le q \le n - 1}(q^2 + (n - q - 1)^2) = (n - 1)^2,
\]
which give us the bound
\begin{equation*}
\begin{aligned}
  T(n) &\ge c (n - 1)^2 + \Theta(n)\\
       &=   cn^2 - 2cn + c + \Theta(n)\\
       &=   cn^2 - c(2n - 1) + \Theta(n)\\
       &\ge cn^2,
\end{aligned}
\end{equation*}
since we pick the constant $c$ small enough so that the $\Theta(n)$ term
dominates the $c(2n - 1)$ term, which implies
\[
  T(n) = \Omega(n^2).
\]
\end{framed}

\item[7.4{-}2]{Show that quicksort's best-case running time is $\Omega(n \lg n)$.}

\begin{framed}
Let $T(n)$ be the best-case time of \textsc{Quicksort} on an input of size
$n$. We have the recurrence
\[
  T(n) = \min_{0 \le q \le n - 1}(T(q) + T(n - q - 1)) + \Theta(n).
\]

We guess $T(n) \ge cn \lg n$ for some constant $c$. Substituting into the
recurrence yields
\begin{equation*}
\begin{aligned}
  T(n) &\ge \min_{0 \le q \le n - 1}(cq \lg q + c(n - q - 1) \lg (n - q - 1)) + \Theta(n)\\
       &=   c \cdot \min_{0 \le q \le n - 1}(q \lg q + (n - q - 1) \lg (n - q - 1)) + \Theta(n).
\end{aligned}
\end{equation*}

For simplicify, assume that $n$ is odd. The expression $c q \lg q + (n - q - 1)
\lg (n - q - 1)$ achieves a minimum when
\[
  q = n - q - 1,
\]
which implies
\[
  q = \frac{n - 1}{2}.
\]
Thus, we have
\begin{equation*}
\begin{aligned}
  T(n) &\ge c \left(\frac{n - 1}{2}\right) \lg \left(\frac{n - 1}{2}\right) +
            c\left(n - \frac{n - 1}{2} - 1\right) \lg \left(n - \frac{n - 1}{2} - 1\right) + \Theta(n)\\
       &= c(n - 1) \lg \left(\frac{n - 1}{2}\right) + \Theta(n)\\
       &= c(n - 1) \lg (n - 1) - c(n - 1) + \Theta(n)\\
       &= cn \lg (n - 1) - c \lg (n - 1) - c (n - 1) + \Theta(n)\\
       &\ge cn \lg \left(\frac{n}{2}\right) - c \lg (n - 1) - c(n - 1) + \Theta(n) & \text{($n \ge 2$)}\\
       &= cn \lg n - cn - c \lg (n - 1) - c(n - 1) + \Theta(n)\\
       &= cn \lg n - c (2n + \lg (n - 1) - 1) + \Theta(n)\\
       &\ge cn \lg n,
\end{aligned}
\end{equation*}
since we pick the constant $c$ small enough so that the $\Theta(n)$ term
dominates the $c(2n + \lg (n - 1) - 1)$ term, which implies
\[
  T(n) = \Omega(n \lg n).
\]
\end{framed}

\item[7.4{-}3]{Show that the expression $q^2 + (n - q - 1)^2$ achieves a maximum
over $q = 0, 1, \dots, n - 1$ when $q = 0$ or $q = n - 1$.}

\begin{framed}
Let $f(q) = q^2 + (n - q - 1)^2$. We have
\[
  f'(q) = 2q + 2(n - q - 1) \cdot (-1) = 4q -2n + 2,
\]
and
\[
  f''(q) = 4.
\]

Since the second derivative is positive, $f(q)$ achieves a maximum over $0, 1,
\dots, n - 1$ at either endpoint. But we have
\[
  f(0) = 0^2 + (n - 1)^2 = (n - 1)^2 + (n - (n - 1) - 1)^2 = f(n - 1),
\]
which implies that both endpoints are maximum.
\end{framed}

\item[7.4{-}4]{Show that \textsc{Randomized-Quicksort's} expected running time
is $\Omega(n \lg n)$.}

\begin{framed}
Combining equations $(7.2)$ and $(7.3)$, we get
\begin{equation*}
\begin{aligned}
  \text{E}[X] &=   \sum_{i = 1}^{n - 1} \sum_{j = i + 1}^{n} \frac{2}{j - i + 1}\\
              &=   \sum_{i = 1}^{\floor{n/2}} \sum_{k = 1}^{n - i} \frac{2}{k + 1} +
                   \sum_{i = \floor{n/2} + 1}^{n - 1} \sum_{k = 1}^{n - i} \frac{2}{k + 1}\\
              &\ge \sum_{i = 1}^{\floor{n/2}} \sum_{k = 1}^{n - i} \frac{2}{k + 1}\\
              &\ge \sum_{i = 1}^{\floor{n/2}} \sum_{k = 1}^{n/2} \frac{2}{k + 1}\\
              &\ge \sum_{i = 1}^{\floor{n/2}} \sum_{k = 1}^{n/2} \frac{1}{k} & \text{(since $k \ge 1$)}\\
              &= \Bigl\lfloor \frac{n}{2} \Bigr\rfloor \cdot \left(\lg \left( \frac{n}{2} \right) + O(1) \right) & \text{(approx. of harmonic number)}\\
              &= \Omega(n \lg n).
\end{aligned}
\end{equation*}
\end{framed}

\item[7.4{-}5]{We can improve the running time of quicksort in practice by
taking advantage of the fast running time of insertion sort when its input is
``nearly'' sorted. Upon calling quicksort on a subarray with fewer than
$k$ elements, let it simply return without sorting the subarray. After the
top-level call to quicksort returns, run insertion sort on the entire array
to finish the sorting process. Argue that this sorting algorithm runs in
$O(nk + n \lg(n/k))$ expected time. How should we pick $k$, both in theory and
in practice?}

\begin{framed}
Lets first analyze the modified \textsc{Quicksort}. As in the standard
\textsc{Quicksort}, it is easy to see that the worst-case of this modified
version is still $O(n^2)$. As for the expected time, we can use a similar
argument to the one used on Section 7.2, in which we saw that any split of
constant proportionality on \textsc{Quicksort} yields a recursion tree of
depth $\Theta(\lg n)$. Assume that \textsc{Partition} on this modified
\textsc{Quicksort} always give a 99-to-1 split. The height $h$ of the recursion
tree would be
\[
  \frac{n}{(100/99)^h} = k \rightarrow h = \log_{100/99} \frac{n}{k} \rightarrow h = \Theta\left(\lg \frac{n}{k}\right).
\]
Since each recursion level has cost at most $cn$, the expected total cost of
this modified \textsc{Quicksort} is $O(n \lg \frac{n}{k})$. As for the cost of
the \textsc{Insertion-Sort}, note after running the modified \textsc{Quicksort},
every element will be out of order by at most $k$ positions. Thus, each
iteration of the outer loop of \textsc{Insertion-Sort} will make at most $k$
swaps, which gives a running time of $O(nk)$. Finally, the cost of the whole
algorithm is
\[
  O(nk) + O\left(n \lg \left(\frac{n}{k}\right)\right) = O\left(nk + n \lg \left(\frac{n}{k}\right)\right).
\]
\end{framed}

\newpage

\item[7.4{-}6]{($\star$) Consider modifying the \textsc{Partition} procedure by
randomly picking three elements from array $A$ and partitioning about their
median (the middle value of the three elements). Approximate the probability of
getting at worst an $\alpha$-to-$(1 - \alpha)$ split, as a function of
$\alpha$ in the range $0 < \alpha < 1$.}

\begin{framed}
First assume $0 < \alpha \le 1/2$. There four ways to get a split worse than
$\alpha$-to-$(1 - \alpha)$:
\begin{enumerate}
  \item The index of exactly two elements are smaller than $\alpha n$
  \item The index of exactly two elements are greater than $n - \alpha n$.
  \item The index of all three elements are smaller than $\alpha n$.
  \item The index of all three elements are greater than $n - \alpha n$.
\end{enumerate}
Since we want an approximation, assume that we can repeat the same element. The
probability of cases (a) and (b) is
\[
  \text{Pr}\{(a)\} = \text{Pr}\{(b)\} =
  3 \cdot \left(\frac{\alpha n}{n} \cdot \frac{\alpha n}{n} \cdot
                \frac{(1 - \alpha) n}{n}\right) =
  3 \alpha^2 - 3 \alpha^3,
\]
in which the multiplication on the left is needed since there are
$\binom{3}{1} = 3$ ways to pick one of three elements outside the desired range.
The probability of cases (c) and (d) is
\[
  \text{Pr}\{(c)\} = \text{Pr}\{(d)\} =
  \frac{\alpha n}{n} \cdot \frac{\alpha n}{n} \cdot \frac{\alpha n}{n} =
  \alpha^3.
\]

Thus, the probability of getting a split worse than $\alpha$-to-$(1 - \alpha)$ is
\begin{equation*}
\begin{aligned}
  1 - \text{Pr}\{(a) + (b) + (c) + (d)\}
  &= 1 - \left(\text{Pr}\{(a)\} + \text{Pr}\{(b)\} + \text{Pr}\{(c)\} + \text{Pr}\{(d)\}\right)\\
  &= 1 - \left((3 \alpha^2 - 3 \alpha^3) + (3 \alpha^2 - 3 \alpha^3) + \alpha^3 + \alpha^3\right)\\
  &= 1 - (6 \alpha^2 - 4 \alpha^3)\\
  &= 1 - 6 \alpha^2 + 4 \alpha^3.
\end{aligned}
\end{equation*}

The proof is similar for $1/2 \le \alpha < 1$ and the result is the same.
\end{framed}

\end{enumerate}

\newpage

{\large Problems}

\begin{enumerate}

\item[7{-}1]{\textbf{\emph{Hoare partition correctness}}\\
The version of \textsc{Partition} given in this chapter is not the original
partitioning algorithm. Here is the original partition algorithm, which is
due to C.A.R. Hoare:

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Hoare-Partition}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r}}{%
 $x = A[p]$\;
 $i = p - 1$\;
 $j = r + 1$\;
\While{\texttt{\upshape{True}}}{%
   \Repeat{$A[j] \le x$}{%
     $j = j - 1$\; }
   \Repeat{$A[i] \ge x$}{%
     $i = i + 1$\; }
   \If{$i < j$}{%
     exchange $A[i]$ with $A[j]$\; }
   \Else{%
     \Return{$j$}\; } } }
\end{algorithm}

\begin{enumerate}
\item[\textbf{a.}]{Demonstrate the operation of \textsc{Hoare-Partition} on the array
$A = \langle 13, 19, 9, 5, 12, 8, 7, 4, 11, 2, 6, 21 \rangle$, showing the
values of the array and auxiliary values after each iteration of the
\textbf{while} loop in lines 4{--}13.}
\end{enumerate}

The next three questions ask you to give a careful argument that the procedure
\textsc{Hoare-Partition} is correct. Assuming that the subarray $A[p, \dots, r]$
contains at least two elements, prove the following:

\begin{enumerate}
\item[\textbf{b.}]{The indices $i$ and $j$ are such that we never access an
element of $A$ outside the subarray $A[p, \dots, r]$.}
\item[\textbf{c.}]{When \textsc{Hoare-Partition} terminates, it returns a value
$j$ such that $p \le j < r$.}
\item[\textbf{d.}]{Every element of $A[p, \dots, j]$ is less than or equal to
every element of $A[j + 1, \dots, r]$ when \textsc{Hoare-Partition} terminates.}
\end{enumerate}

The \textsc{Partition} procedure in Section 7.1 separates the pivot value
(originally in $A[r]$) from the two partitions it forms. The
\textsc{Hoare-Partition} procedure, on the other hand, always places the pivot
value (originally in $A[p]$) into one of the two partitions $A[p, \dots, j]$
and $A[j + 1, \dots, r]$. Since $p \le j < r$, this split is always nontrivial.

\begin{enumerate}
\item[\textbf{e.}]{Rewrite the \textsc{Quicksort} procedure to use
\textsc{Hoare-Partition}.}
\end{enumerate}
}

\begin{framed}
\begin{enumerate}
\item{The operation is illustrated below:

\begin{center}
\begin{tabular}{cccccccccccccc}
  $i$ & $x$                 &                     &   &   &    &   &   &   &     &                    &                    &    & $j$\\
      & 13                  & 19                  & 9 & 5 & 12 & 8 & 7 & 4 & 11  & 2                  & 6                  & 21 &    \\
      & $x, i$              &                     &   &   &    &   &   &   &     &                    & $j$                &    &    \\
      & \textcolor{red}{13} & 19                  & 9 & 5 & 12 & 8 & 7 & 4 & 11  & 2                  & \textcolor{red}{6} & 21 &    \\
      &                     & $i$                 &   &   &    &   &   &   &     & $j$                & $x$                &    &    \\
      & 6                   & \textcolor{red}{19} & 9 & 5 & 12 & 8 & 7 & 4 & 11  & \textcolor{red}{2} & 13                 & 21 &    \\
      &                     &                     &   &   &    &   &   &   & $j$ & $i$                & $x$                &    &    \\
      & 6                   & 2                   & 9 & 5 & 12 & 8 & 7 & 4 & 11  & 19                 & 13                 & 21 &
\end{tabular}
\end{center}
}
\item{Consider the following \textbf{\emph{loop invariant}}:
\begin{quote}
At the beginning of each iteration of the \textbf{while} loop of lines 4{-}13,
$i < j$ and the subarray $A[p, \dots, j - 1]$ contains at least one element that
is lower than or equal to $A[x]$. Similarly, the subarray $A[i + 1, \dots, r]$
contains at least one element that is greater than or equal to $A[x]$.
\end{quote}
We need to show that this loop invariant is true prior to the first iteration,
that each iteration of the loop maintains the invariant, and that the invariant
provides a useful property to show correctness when the loop terminates.
\begin{itemize}
  \item \textbf{Initialization.} Prior to the \textbf{while} loop of lines 4-13,
    $i = p - 1$ and $j = r - 1$. Since
    $A[i + 1, \dots, r] = A[p, \dots, j - 1] = A[p, \dots, r]$, the
    element $A[x]$ is present in both subarrays. Thus, the loop invariant is
    valid before the loop.
  \item \textbf{Maintenance.} From the loop invariant, the \textbf{for} loops of
    lines 5-7 and 8-10 will both stop on valid indices $i$ and $j$. The loop
    only goes to the next iteration if $i < j$. In that case, the elements
    $A[i]$ and $A[j]$ are exchanged, which ensures the loop invariant for the
    next iteration.
  \item \textbf{Termination.} At termination, the \textbf{for} loops of lines
    5-7 and 8-10 will stop on valid indices $i$ and $j$ such that $i \ge j$ and
    the loop terminates before going to the next iteration.
\end{itemize}

The above loop invariant ensures that the \text{for} loops of lines 5-7 and
8-10 will never make $j < p$ or $i > r$, which implies that the
\textsc{Hoare-Partition} procedure always access elements within the subarray
$A[p, \dots, r]$.
}
\item{From item (b), we have the lower bound $j \ge p$. As for the upper bound
of $j$, note that:
\begin{enumerate}
  \item If $A[r] > x$, the condition on line 7 will be false at least one time,
    which implies that line 6 will be executed at least twice. Since the initial
    value of $j$ is $r + 1$, in this case we have $j < r$.
  \item If $A[r] \le x$, $A[r]$ will be exchanged with $A[p]$ in the first
    iteration of the \textbf{while} loop and line 6 will be executed for the
    second time in the next iteration. Thus, in this case we also have $j < r$.
\end{enumerate}
These observations give us the bound $p \le j < r$.
}
\item{Consider the following \textbf{\emph{loop invariant}}:
\begin{quote}
At the beginning of each iteration of the \textbf{while} loop of lines 4-13,
every element of the subarray $A[p, \dots, \min(i, j)]$ is less than or equal
to every element of the subarray $A[j + 1, \dots, r]$.
\end{quote}
We need to show that this loop invariant is true prior to the first iteration,
that each iteration of the loop maintains the invariant, and that the invariant
provides a useful property to show correctness when the loop terminates.
\begin{itemize}
\item \textbf{Initialization.} Prior to the \textbf{while} loop, $i = p - 1$,
$j = r + 1$. Since the subarrays $A[p, \dots, i]$ and $A[j, \dots, r]$ are
empty, the loop invariant is trivially satisfied.
\item \textbf{Maintenance.} To see that each iteration maintains the loop
invariant, note that the \textbf{for} loops of lines 5-7 and 8-10 will decrease
$j$ and increase $i$ until find an $A[j] \le x$ and an $A[i] \ge x$,
respectivelly. At this point, the loop invariant (of previous iteration)
along with the conditions of lines 7 and 10 ensures that every element of
$A[p, \dots, i - 1]$ is less than or equal to every element of
$A[j + 1, \dots, r]$. The only possible exceptions to the loop invariant in this
iteration are the elements $A[i]$ and $A[j]$. Since $A[i] \ge x$ and
$A[j] \le x$, we have $A[i] \ge A[j]$. To go to the next iteration line 11
must be valid and the exchange of $A[i]$ with $A[j]$ at line 12 maintains the
loop invariant.
\item \textbf{Termination.} At termination, the \textbf{for} loop of lines 5-7
and 8-10 will stop on indices $i$ and $j$ such that $i \ge j$. Since
$\min(i, j) = j$, the loop invariant (of previous iteration) along with the
conditions of lines 7 and 10 ensures that every element of $A[p, \dots, j]$
  will be less than or equal to every element of $A[j + 1, \dots, r]$.
\end{itemize}
}
\item{The pseudocode is stated below.

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Hoare-Quicksort}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r}}{%
 \If{$p < r$}{%
   $q = \texttt{Hoare-Partition}(A, p, r)$\;
   \texttt{Hoare-Partition}$(A, p, q)$\;
   \texttt{Hoare-Partition}$(A, q + 1, r)$\; } }
\end{algorithm}
}
\end{enumerate}
\end{framed}

\newpage

\item[7{-}2]{\textbf{\emph{Quicksort with equal element values}}\\
The analysis of the expected running time of randomized quicksort in Section
7.4.2 assumes that all element values are distinct. In this problem, we examine
what happens when they are not.

\begin{enumerate}
\item[\textbf{a.}]{Suppose that all element values are equal. What would be
randomized quicksort's running time in this case?}

\item[\textbf{b.}]{The \textsc{Partition} procedure returns an index $q$ such
that each element of $A[p, \dots, q - 1]$ is less than or equal to $A[q]$ and
each element of $A[q + 1, \dots, r]$ is greater than $A[q]$. Modify the
\textsc{Partition} procedure to produce a procedure
\textsc{Partition'}$(A, p, r)$, which permutes the elements of $A[p, \dots, r]$
and returns two indices $q$ and $t$, where $p \le q \le t \le r$, such that
\begin{itemize}
\item{all elements if $A[q, \dots, t]$ are equal,}
\item{each element of $A[p, \dots, q - 1]$ is less than $A[q]$, and}
\item{each element of $A[r + 1, \dots, r]$ is greater than $A[q]$.}
\end{itemize}

Like \textsc{Partition}, your \textsc{Partition'} procedure should take
$\Theta(r - p)$ time.
}
\end{enumerate}

\begin{enumerate}
\item[\textbf{c.}]{Modify the \textsc{Randomized-Partition} procedure to call
\textsc{Partition'}, and name the new procedure \textsc{Randomized-Partition'}.
Then modify the \textsc{Quicksort} procedure to produce a procedure
\textsc{Quicksort'}$(A, p, r)$ that calls \textsc{Randomized-Partition'} and
recurses only on partitions of elements not known to be equal to each other.}

\item[\textbf{d.}]{Using \textsc{Quicksort'}, how would you adjust the analysis
in Section 7.4.2 to avoid the assumption that all elements are distinct?}
\end{enumerate}
}

\begin{framed}
\begin{enumerate}
\item{In this case, the condition on line 4 of the \textsc{Partition} procedure
will always be valid and it will always give ``bad'' splits
($(n - 1)$-to-0). Thus, the running time will be $\Theta(n^2)$.}
\item{This item is similar to the Question 7.1-2. The pseudocode of the modified
\textsc{Partition} procedure is stated below.

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Partition'}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r}}{%
  $x = A[r]$\;
  $i = j = p - 1$\;
  \For{$k = p$ \KwTo $r - 1$}{%
    \If{$A[k] \le x$}{%
      $j = j + 1$\;
      exchange $A[j]$ with $A[k]$\;
      \If{$A[j] < x$}{%
        $i = i + 1$\;
        exchange $A[i]$ with $A[j]$\;
      }
    }
  }
  exchange $A[j + 1]$ with $A[r]$\;
  $q = i + 1$\;
  $t = j + 1$\;
  \Return{$q, t$}\; }
\end{algorithm}
}
\item{The pseudocode of the modified \textsc{Randomized-Partition}
\textsc{Quicksort} procedures are stated below.

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Randomized-Partition'}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r}}{%
  $i = \texttt{Random}(p, r)$\;
  exchange $A[r]$ with $A[i]$\;
  \Return{\texttt{\upshape{Partition'}}$(A, p, r)$}\; }
\end{algorithm}

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Quicksort'}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r}}{%
  \If{$p < r$}{%
    $q, t = \texttt{Randomized-Partition'}(A, p, r)$\;
    \texttt{Quicksort'}$(A, p, q - 1)$\;
    \texttt{Quicksort'}$(A, t + 1, r)$\; } }
\end{algorithm}
}
\item{We just need to rewrite the sentence
\begin{quote}
  In general, because we assume that element values are distinct, once a pivot
  $x$ is chosen with $z_i < x < z_j$, we know that $z_i$ and $z_j$ cannot be
  compared at any subsequent time.
\end{quote}
as
\begin{quote}
  Once a pivot $z_q$ is chosen with $z_i \le z_q \le z_j$, such that
  $i \neq q$ and $j \neq q$, we know that $z_i$ and $z_j$ cannot be compared at
  any subsequent time.
\end{quote}
}
\end{enumerate}
\end{framed}

\newpage

\item[7{-}3]{\textbf{\emph{Alternative quicksort analysis}}\\
An alternative analysis of the running time of randomized quicksort focuses on
the expected running time of each individual recursive call to
\textsc{Randomized-Quicksort}, rather than on the number of comparisons
performed.

\begin{enumerate}
\item[\textbf{a.}]{Argue that, given an array of size $n$, the probability that
any particular element is chosen as the pivot is $1/n$. Use this to define
indicator random variables
$X_i = \text{I}\{i\text{th smallest element is chosen as the pivot}\}$. What is
$\text{E}[X_i]$?}

\item[\textbf{b.}]{Let $T(n)$ be a random variable denoting the running time of
quicksort on an array of size $n$. Argue that
\[
  \text{E}[T(n)] = \text{E}\left[ \sum_{q = 1}^{n}{X_q (T(q - 1) + T(n - q) + \Theta(n))} \right].
\]}

\item[\textbf{c.}]{Show that we can rewrite equation (7.5) as
\[
  \text{E}[T(n)] = \frac{2}{n} \sum_{q = 2}^{n - 1} \text{E}[T(q)] + \Theta(n).
\]}

\item[\textbf{d.}]{Show that
\[
  \sum_{k = 2}^{n - 1}{k \lg k} \le \frac{1}{2} n^2 \lg n - \frac{1}{8} n^2.
\]
(\emph{Hint:} Split the summation into two parts, one for
$k = 2, 3, \dots, \ceil{n/2} - 1$ and one for $k = \ceil{n/2}, \dots, n - 1$.)}

\item[\textbf{e.}]{Using the bound from equation (7.7), show that the recurrence
in equation (7.6) has the solution $\text{E}[T(n)] = \Theta(n \lg n)$.
(\emph{Hint:} Show, by substitution, that $\text{E}[T(n)] \le a n \lg n$ for
sufficiently large $n$ and for some positive constant $a$.)}
\end{enumerate}
}

\begin{framed}
\begin{enumerate}
\item{In each recursive call to \textsc{Randomized-Quicksort}, the pivot is
randomly chosen among the $n$ elements of the input subarray. Thus, we have
\[
  \text{E}[X_i] = \text{Pr}\{X_i = 1\} = \frac{1}{n}.
\]
}
\item{Each call to \textsc{Partition} tales $\Theta(n)$ and once the $q$th }
\item{Each call to \textsc{Quicksort} selects a pivot $q$, such that
$1 \le q \le n$, that partitions the array into two subarrays of sizes $q - 1$
and $n - q$. The indicator random variable $X_q$ indicates whether the element
with index $q$ is selected as the pivot. Since only one element can be chosen as
the pivot at a given call to \textsc{Quicksort} and the running time of each
call is $\Theta(n)$, the running time of \textsc{Quicksort} can be written as
\[
  T(n) = \sum_{q = 1}^{n} X_q ( T(q - 1) + T(n - q) + \Theta(n) ),
\]
which implies
\[
  \text{E}[T(n)] = \text{E}\left[\sum_{q = 1}^{n} X_q (T(q - q) + T(n - q) +
                                                  \Theta(n)) \right].
\]
}
\item{
\begin{equation*}
\begin{aligned}
\text{E}[T(n)]
&= \text{E}\left[\sum_{q = 1}^{n} X_q (T(q - q) + T(n - q) + \Theta(n)) \right]\\
&= \sum_{q = 1}^{n} \text{E}[ X_q (T(q - 1) + T(n - q) + \Theta(n)) ]\\
&= \sum_{q = 1}^{n} \left( \frac{1}{n} \cdot \text{E}[(T(q - 1) + T(n - q) + \Theta(n)) ] \right)\\
&= \frac{1}{n} \cdot \sum_{q = 1}^{n} \text{E}[T(q - 1)] +
   \frac{1}{n} \cdot \sum_{q = 1}^{n} \text{E}[T(n - q)] +
   \frac{1}{n} \cdot \sum_{q = 1}^{n} \Theta(n)\\
&= \frac{1}{n} \cdot \sum_{q = 2}^{n - 1} \text{E}[T(q)] +
   \frac{1}{n} \cdot \Theta(1) +
   \frac{1}{n} \cdot \sum_{q = 2}^{n - 1} \text{E}[T(q)] +
   \frac{1}{n} \cdot \Theta(1) +
   \Theta(n)\\
&= \frac{2}{n} \cdot \sum_{q = 2}^{n - 1} \text{E}[T(q)] +
   \Theta(n).
\end{aligned}
\end{equation*}
}
\item{We guess that
\[
  \text{E}[T(n)] \le a n \lg n,
\]
for some constant $a$. Substituting into the recurrence yields
\begin{equation*}
\begin{aligned}
  \text{E}[T(n)] &\le \frac{2}{n} \sum_{q = 2}^{n - 1} ( a q \lg q ) + \Theta(n)\\
                 &=   \frac{2a}{n} \sum_{q = 2}^{n - 1} ( q \lg q ) + \Theta(n)\\
                 &\le \frac{2a}{n} \left( \frac{1}{2} n^2 \lg n - \frac{1}{8} n^2 \right) + \Theta(n)\\
                 &=   a n \lg n - a \frac{1}{4} n + \Theta(n)\\
                 &\le a n \lg n,
\end{aligned}
\end{equation*}
since we pick the constant $a$ large enough so that the $a (1/4) n$ term
dominates the $\Theta(n)$ term.
}
\end{enumerate}
\end{framed}

\newpage

\item[7{-}4]{\textbf{\emph{Stack depth for quicksort}}\\
The \textsc{Quicksort} algorithm of Section 7.1 contains two recursive calls to
itself. After \textsc{Quicksort} calls \textsc{Partition}, it recursively sorts
the left subarray and then it recursively sorts the right subarray. The second
recursive call in \textsc{Quicksort} is not really necessary; we can avoid it by
using an iterative control structure. This technique, called \textbf{\emph{tail
recursion}}, is provided automatically by good compilers. Consider the following
version of quicksort, which simulates tail recursion:

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Tail-Recursive-Quicksort}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r}}{%
 \While{$p < r$}{%
   // Partition and sort left subarray\;
   $q = \texttt{Partition}(A, p, r)$\;
   \texttt{Tail-Recursive-Quicksort}(A, p, q - 1)\;
   $p = q + 1$\; } }
\end{algorithm}

\begin{enumerate}
\item[\textbf{a.}]{Argue that \textsc{Tail-Recursive-Quicksort}$(A, 1,
A.length)$ correctly sorts the array $A$.}
\end{enumerate}

Compilers usually execute recursive procedures by using a \textbf{\emph{stack}}
that contains pertinent information, including the parameter values, for each
recursive call. The information for the most recent call is at the top of the
stack, and the information for the initial call is at the bottom. Upon calling
a procedure, its information is \textbf{\emph{pushed}} onto the stack; when it
terminates, its information is \textbf{\emph{popped}}. Since we assume that
array parameters are represented by pointers, the information for each procedure
call on the stack requires $O(1)$ stack space. The stack depth is the maximum
amount of \textbf{\emph{stack space}} used at any time during a computation.

\begin{enumerate}
\item[\textbf{b.}]{Describe a scenario in which
\textsc{Tail-Recursive-Quicksort's} stack depth is $\Theta(n)$ on an
$n$-element array.}

\item[\textbf{c.}]{Modify the code for \textsc{Tail-Recursive-Quicksort} so that
the worst-case stack depth is $\Theta(\lg n)$. Maintain the $O(n \lg n)$
expected running time of the algorithm.}
\end{enumerate}
}

\begin{framed}
\begin{enumerate}
\item{After the \textsc{Partition} call, the algorithm calls itself with
arguments $A, p, q - 1$, sets $p = q + 1$, and repeat the same operations. Since
the only difference to the next iteration is the new value of $p$, the loop
is similar as calling itself with arguments $A, q + 1, r$. Thus,
\textsc{Tail-Recursive-Quicksort}} produces the same result of
\textsc{Quicksort}.
\item{If the \textsc{Partition} procedure always select the largest element of
the array as the pivot, the left subarray will always have size $n - 1$, and the
stack depth will be $\Theta(n)$.}
\item{To reduce the maximum stack depth, we should always give to the tail
recursion the larger of the two subproblems. The updated pseudocode is stated
below.

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Tail-Recursive-Quicksort-Improved}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r}}{%
 \While{$p < r$}{%
   // Partition and sort left subarray\;
   $q = \texttt{Partition}(A, p, r)$\;
   \If{$q < (p + r)/2$}{%
     \texttt{Tail-Recursive-Quicksort}(A, p, q - 1)\;
     $p = q + 1$\; }
   \Else{%
     \texttt{Tail-Recursive-Quicksort}(A, q + 1, r)\;
     $r = q - 1$\;
   } } }
\end{algorithm}

Each recursive call reduces the problem size by at least half. Thus, the stack
depth is $O(\lg n)$.
}
\end{enumerate}
\end{framed}

\newpage

\item[7{-}5]{\textbf{\emph{Median-of-3 partition}}\\
One way to improve the \textsc{Randomized-Quicksort} procedure is to partition
around a pivot that is chosen more carefully than by picking a random element
from the subarray. One common approach is the \textbf{\emph{median-of-3}}
method: choose the pivot as the median (middle element) of a set of 3 elements
randomly selected from the subarray. (See Exercise 7.4-6.) For this problem, let
us assume that the elements in the input array $A[1, \dots, n]$ are distinct and
that $n \ge 3$. We denote the sorted output array by $A'[1, \dots, n]$. Using
the median-of-3 method to choose the pivot element $x$, define
$p_i = \text{Pr}\{x = A'[i]\}$.

\begin{enumerate}
\item[\textbf{a.}]{Give an exact formula for $p_i$ as a function of $n$ and $i$
for $i = 2, 3, \dots, n - 1$. (Note that $p_1 = p_n = 0$.)}

\item[\textbf{b.}]{By what amount have we increased the likelihood of choosing
the pivot as $x = A'[\floor{(n + 1)/2}]$, the median of $A[1, \dots, n]$,
compared with the ordinary implementation? Assume that $n \rightarrow \infty$,
and give the limiting ratio of these probabilities.}

\item[\textbf{c.}]{If we define a ``good'' split to mean choosing the pivot as
$x = A'[i]$, where $n/3 \le i \le 2n/3$, by what amount have we increased the
likelihood of getting a good split compared with the ordinary implementation?
(\emph{Hint:} Approximate the sum by an integral.)}

\item[\textbf{d.}]{Argue that in the $\Omega(n \lg n)$ running time of
quicksort, the median-of-3 method affects only the constant factor.}
\end{enumerate}
}

\begin{framed}
\begin{enumerate}
\item{Note that the number of 3-permutations on a set of $n$ elements is
\[
  \frac{n!}{(n - 3)!} = n (n - 1) (n - 2).
\]

To choose the element $i$ as the pivot, one element needs to be within the first
$i - 1$ positions of the array, one elements needs to be within the last $n - i$
positions of the array, and one element needs to be the $i$th element. Also note
that each combination of elements that chooses the element $i$ as the pivot has
$3! = 6$ permutations; hence 6 ways to be selected. Thus, we have
\[
  p_i = \frac{3! \cdot 1 \cdot (i - 1) \cdot (n - i)}{n!/(n - 3)!} = \frac{6 (i - 1) (n - i)}{n (n - 1) (n - 2)}.
\]}
\item{We have
\begin{equation*}
\begin{aligned}
p_{\floor{(n + 1)/2}}
  &=   \frac{6 \cdot \left(\Bigl\lfloor\frac{n + 1}{2}\Bigr\rfloor - 1\right)
                     \left(n - \Bigl\lfloor\frac{n + 1}{2}\Bigr\rfloor\right)}{n (n - 1) (n - 2)}\\
&\le \frac{6 \cdot \left(\frac{n + 1}{2} - 1\right) \left(n - \frac{n + 1}{2}\right)}{n (n - 1) (n - 2)}\\
&=   \frac{6 \cdot \left(\frac{n - 1}{2}\right) \left(\frac{n - 1}{2}\right)}{n (n - 1) (n - 2)}\\
&=   \frac{3}{2} \cdot \frac{(n - 1) (n - 1)}{n (n - 1) (n - 2)}\\
&=   \frac{3}{2} \cdot \frac{(n - 1)}{n (n - 2)}.
\end{aligned}
\end{equation*}
Then, we have the ratio
\[
\lim_{n\to\infty} \frac{\frac{3}{2} \cdot \frac{n - 1}{n (n - 2)}}{\frac{1}{n}}
= \lim_{n\to\infty} \frac{3}{2} \frac{n (n - 1)}{n (n - 2)} = \frac{3}{2} = 1.5.
\]
}
\item{To get a ``good'' split with the median-of-3 method, the pivot can not be
within the first $\floor{n/3}$ elements or within the last $\ceil{n/3}$
elements. Thus, we have
\[
\text{Pr}\{\text{good split with median-of-3}\} = \sum_{i = \ceil{n/3}}^{\floor{2n/3}} p_i
\approx \sum_{i = n/3}^{2n/3} p_i
= \sum_{i = n/3}^{2n/3} \frac{6 (i - 1) (n - i)}{n (n - 1) (n - 2)}
= \frac{6}{n (n - 1) (n - 2)} \cdot \sum_{i = n/3}^{2n/3} (i - 1) (n - i).
\]

Note that
\begin{equation*}
\begin{aligned}
\sum_{x = n/3}^{2n/3} (x - 1) (n - x)
&\approx \int_{n/3}^{2n/3} (x - 1) (n - x) dx\\
&= \int_{n/3}^{2n/3} (nx -x^2 - n + x) dx\\
&= \Eval{-\frac{1}{3} x^3 + \frac{1}{2} x^2 (n + 1) - xn}{n/3}{2n/3}\\
&= \frac{13}{162} n^3 - \frac{1}{6} n^2,
\end{aligned}
\end{equation*}
which implies
\[
 \text{Pr}\{\text{good split with median-of-3}\} \approx \frac{6}{n (n - 1)(n - 2)} \left( \frac{13}{162} n^3 - \frac{1}{6} n^2 \right)
= \frac{\frac{13}{27} n^3 - n^2}{n (n - 1) (n - 2)}.
\]

Then, we have the ratio
\[
\frac{\text{Pr}\{\text{good split with median-of-3}\}}{\text{Pr}\{\text{good split with one pivot}\}}
= \lim_{n\to\infty} \frac{\frac{\frac{13}{27} n^3 - n^2}{n (n - 1) (n - 2)}}{\frac{1}{3}}
= \lim_{n\to\infty} \frac{\frac{\frac{13}{27} n^3 - n^2}{n^3 - n^2 - 2n}}{\frac{1}{3}}
= \lim_{n\to\infty} \frac{\frac{13}{27}}{\frac{1}{3}} \approx 1.44.
\]

}
\item{The only difference is on the choice of the pivot. However, even if the
middle element is always chosen as the pivot (which is the best case), the
height of the recursion tree will be $\Theta(\lg n)$. Since each recursion level
takes $\Theta(n)$, the running time is still $\Omega(n \lg n)$.}
\end{enumerate}
\end{framed}

\newpage

\item[7{-}6]{\textbf{\emph{Fuzzy sorting of intervals}}\\
Consider a sorting problem in which we do not know the numbers exactly. Instead,
for each number, we know an interval on the real line to which it belongs.
That is, we are given $n$ closed intervals of the form $[a_i, b_i]$, where
$a_i \le b_i$. We wish to \textbf{\emph{fuzzy-sort}} these intervals, i.e., to
produce a permutation $\langle i_1, i_2, \dots, i_n \rangle$ of the intervals
such that for $j = 1, 2, \dots, n$, there exist $c_j \in [a_{i_j}, b_{i_j}]$
satisfying $c_1 \le c_2 \le \cdots \le c_n$.

\begin{enumerate}
\item[\textbf{a.}]{Design a randomized algorithm for fuzzy-sorting $n$
intervals.  Your algorithm should have the general structure of an algorithm
that quicksorts the left endpoints (the $a_i$ values), but it should take
advantage of overlapping intervals to improve the running time. (As the
intervals overlap more and more, the problem of fuzzy-sorting the intervals
becomes progressively easier. Your algorithm should take advantage of such
overlapping, to the extent that it exists.)}

\item[\textbf{b.}]{Argue that your algorithm runs in expected time
$\Theta(n \lg n)$ in general, but runs in expected time $\Theta(n)$ when all of
the intervals overlap (i.e., when there exists a value $x$ such that
$x \in [a_i, b_i]$ for all $i$). Your algorithm shoukd not be checking for this
case explicitly; rather, its performance should naturally improve as the amount
of overlap increases.}
\end{enumerate}
}

\begin{framed}
\begin{enumerate}
\item{
Note that any subset of intervals that share a common point are already sorted.
Using this notion, we can sort an array of fuzzy intervals with an algorithm
similar to quicksort, but with a customized partition procedure that returns two
indices $q$ and $t$, where $p \le q \le t \le r$, such that
\begin{itemize}
\item There exist $x$ such that $x \in [a_i, b_i]$ for all $q \le i \le t$. That
is, any permutation of the subarray $A[q, \dots, t]$ is sorted;
\item For all $j < q$, there exist $c_j \in [a_j, b_j]$ such that $c_j < b_i$
for all $q \le i \le t$. That is, every interval of $A[p, \dots, q - 1]$ can
stay before every interval of $A[q, \dots, t]$ in the sorted array;
\item For all $j > t$, there exist $c_j \in [a_j, b_j]$ such that $c_j > a_i$
for all $q \le i \le t$. That is, every interval of $A[t + 1, \dots, r]$ can
stay after every interval of $A[q, \dots, t]$ in the sorted array.
\end{itemize}

The pseudocode is stated below.

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Fuzzy-Partition}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r}}{%
  $a = A[r].a$\;
  $b = A[r].b$\;
  $i = j = p - 1$\;
  \For{$k = p$ \KwTo $r - 1$}{%
    // $A[k]$ can be placed before the pivot\;
    \If{$A[k].a \le b$}{%
      $j = j + 1$\;
      exchange $A[j]$ with $A[k]$\;
      // intervals ($A[k]$ and pivot) do not overlap\;
      \If{$A[j].b < a$}{%
        $i = i + 1$\;
        exchange $A[i]$ with $A[j]$\;
      }
      // intervals ($A[k]$ and pivot) overlap\;
      \Else{%
        \If{$A[k].a > a$}{%
          $a = A[k].a$\;
        }
        \If{$A[k].b < b$}{%
          $b = A[k].b$\;
        }
      }
    }
  }
  exchange $A[j + 1]$ with $A[r]$\;
  $q = i + 1$\;
  $t = j + 1$\;
  \Return{$q, t$}
}
\end{algorithm}

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Fuzzy-Randomized-Partition}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r}}{%
  $i = \texttt{Random}(p, r)$\;
  exchange $A[r]$ with $A[i]$\;
  \Return{\upshape{\texttt{Fuzzy-Partition}}$(A, p, r)$}\; }
\end{algorithm}

\begin{algorithm}[H]
\SetAlgoNoEnd\DontPrintSemicolon
\BlankLine
\SetKwFunction{algo}{Fuzzy-Sort}
\SetKwProg{myalg}{}{}{}
\nonl\myalg{\algo{A, p, r}}{%
  \If{$p < r$}{%
    $q, t = \texttt{Fuzzy-Randomized-Partition}(A, p, r)$\;
    \texttt{Fuzzy-Sort}$(A, p, q - 1)$\;
    \texttt{Fuzzy-Sort}$(A, t + 1, r)$\; } }
\end{algorithm}
}

\newpage

\item{When all intervals share a common point, the array is already sorted. In
this case, there will be only one call to \textsc{Fuzzy-Partition}, which will
return $q = p$ and $t = r$. Thus, the algorithm will run in $\Theta(n)$.

The general case is a little tricky to proof.}
\end{enumerate}
\end{framed}

\end{enumerate}

\end{document}
